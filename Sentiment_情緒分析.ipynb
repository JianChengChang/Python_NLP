{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from future.utils import iteritems\n",
    "from builtins import range\n",
    "\n",
    "\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# from http://www.lextek.com/manuals/onix/stopwords1.html\n",
    "stopwords = set(w.rstrip() for w in open('./stopwords.txt'))\n",
    "\n",
    "# 另一個 stopwords 的來源\n",
    "# from nltk.corpus import stopwords\n",
    "# stopwords.words('english')\n",
    "\n",
    "# 讀正向與負向 reviews\n",
    "# data courtesy of http://www.cs.jhu.edu/~mdredze/datasets/sentiment/index2.html\n",
    "positive_reviews = BeautifulSoup(open('./electronics/positive.review', encoding='utf-8').read(), features=\"html5lib\")\n",
    "positive_reviews = positive_reviews.findAll('review_text')\n",
    "\n",
    "negative_reviews = BeautifulSoup(open('./electronics/negative.review', encoding='utf-8').read(), features=\"html5lib\")\n",
    "negative_reviews = negative_reviews.findAll('review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基於nltk自建 tokenizer\n",
    "# 下載以下corpus\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(s):\n",
    "    s = s.lower() # downcase\n",
    "    tokens = nltk.tokenize.word_tokenize(s) # 將字串改為tokens\n",
    "    tokens = [t for t in tokens if len(t) > 2] # 去除短字\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens] # 單字個別統一詞性\n",
    "    tokens = [t for t in tokens if t not in stopwords] # 去除 stopwords\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先產生 word-to-index map 再產生 word-frequency vectors\n",
    "# 同時儲存 tokenized 版本未來不需再做 tokenization\n",
    "word_index_map = {}\n",
    "current_index = 0\n",
    "positive_tokenized = []\n",
    "negative_tokenized = []\n",
    "orig_reviews = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(word_index_map): 10950\n"
     ]
    }
   ],
   "source": [
    "for review in positive_reviews:\n",
    "    orig_reviews.append(review.text)\n",
    "    tokens = my_tokenizer(review.text)\n",
    "    positive_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index += 1\n",
    "\n",
    "for review in negative_reviews:\n",
    "    orig_reviews.append(review.text)\n",
    "    tokens = my_tokenizer(review.text)\n",
    "    negative_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index += 1\n",
    "\n",
    "print(\"len(word_index_map):\", len(word_index_map))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's create our input matrices\n",
    "def tokens_to_vector(tokens, label):\n",
    "    x = np.zeros(len(word_index_map) + 1) # 最後一個元素是標記\n",
    "    for t in tokens:\n",
    "        i = word_index_map[t]\n",
    "        x[i] += 1\n",
    "    x = x / x.sum() # 正規化數據提升未來準確度\n",
    "    x[-1] = label\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7826315789473685\n",
      "Test accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "N = len(positive_tokenized) + len(negative_tokenized)\n",
    "# (N x D+1) 矩陣 - 擺在一塊將來便於shuffle\n",
    "data = np.zeros((N, len(word_index_map) + 1))\n",
    "i = 0\n",
    "for tokens in positive_tokenized:\n",
    "    xy = tokens_to_vector(tokens, 1)\n",
    "    data[i,:] = xy\n",
    "    i += 1\n",
    "\n",
    "for tokens in negative_tokenized:\n",
    "    xy = tokens_to_vector(tokens, 0)\n",
    "    data[i,:] = xy\n",
    "    i += 1\n",
    "\n",
    "# shuffle data 創造 train/test splits\n",
    "# 多次嘗試!\n",
    "orig_reviews, data = shuffle(orig_reviews, data)\n",
    "\n",
    "X = data[:,:-1]\n",
    "Y = data[:,-1]\n",
    "\n",
    "# 最後 100 列是測試用\n",
    "Xtrain = X[:-100,]\n",
    "Ytrain = Y[:-100,]\n",
    "Xtest = X[-100:,]\n",
    "Ytest = Y[-100:,]\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"Train accuracy:\", model.score(Xtrain, Ytrain))\n",
    "print(\"Test accuracy:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit -0.6383819953871575\n",
      "bad -0.6340777117234015\n",
      "cable 0.6982179574086965\n",
      "time -0.5640300989897066\n",
      "'ve 0.655178150053499\n",
      "month -0.7467362618557694\n",
      "sound 0.9825240290118801\n",
      "lot 0.7622980207365171\n",
      "you 1.1094593091925704\n",
      "n't -1.943733571364344\n",
      "easy 1.6836168388295691\n",
      "quality 1.5603155867294634\n",
      "company -0.572826239173928\n",
      "item -0.9139598186786306\n",
      "wa -1.5156506176657576\n",
      "perfect 1.0010020132130657\n",
      "fast 0.9553067131169514\n",
      "ha 0.7008564250096163\n",
      "price 2.7438746775261404\n",
      "value 0.56598463281185\n",
      "money -1.102530236901507\n",
      "memory 0.9940923247948501\n",
      "picture 0.5439149539214081\n",
      "buy -0.8071889061883898\n",
      "bit 0.6421528963991194\n",
      "happy 0.6435999840157859\n",
      "pretty 0.7377918532381874\n",
      "doe -1.2439208969292936\n",
      "highly 1.0701941673442006\n",
      "recommend 0.6291030534005992\n",
      "fit 0.5445615317377329\n",
      "customer -0.6661219907981996\n",
      "support -0.8166675272343501\n",
      "little 0.8716267875495463\n",
      "worth 0.5146614284614226\n",
      "sent -0.5362256001751562\n",
      "returned -0.7629686453217384\n",
      "excellent 1.3834379231338627\n",
      "love 1.1848196718157893\n",
      "home 0.5071551300250631\n",
      "piece -0.5167229085290139\n",
      "week -0.7798747549818846\n",
      "using 0.550018837321576\n",
      "laptop 0.5381207563465442\n",
      "video 0.5992913376017354\n",
      "poor -0.8088913214206382\n",
      "look 0.5230908015637905\n",
      "then -1.161774036199237\n",
      "tried -0.7644019511479433\n",
      "try -0.676073444715597\n",
      "space 0.6098050229360109\n",
      "comfortable 0.6614256498398893\n",
      "hour -0.5610815870319923\n",
      "expected 0.5677853878314134\n",
      "speaker 0.9185321628366219\n",
      "warranty -0.5942948900307445\n",
      "stopped -0.5623518830642055\n",
      "returning -0.5371076077541821\n",
      "paper 0.5158005601174822\n",
      "terrible -0.5224212759578167\n",
      "return -1.177874508960688\n",
      "waste -0.9996885244825015\n",
      "refund -0.6030533575443181\n"
     ]
    }
   ],
   "source": [
    "# 列出每個字的正負 weight\n",
    "# 用不同的 threshold values!\n",
    "threshold = 0.5\n",
    "for word, index in iteritems(word_index_map):\n",
    "    weight = model.coef_[0][index]\n",
    "    if weight > threshold or weight < -threshold:\n",
    "        print(word, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most wrong positive review (prob = 0.34356828537617684, pred = 0.0):\n",
      "\n",
      "I agree with the previous review.  This phone cord worked twice.  Now, it only retracts about half way, and keeps getting worse.  I'm returning it for a refund.  Don't waste your time with this\n",
      "\n",
      "Most wrong negative review (prob = 0.5975422644368281, pred = 1.0):\n",
      "\n",
      "I was looking for a new pair of headphones to compliment my brand new ipod nano when I ran across these on a website. I was a little hesitant at first because I don't think I ever spent over $40 on a pair of headphones. I finally decided to invest in these because I spend most of my free time listening to music. I received these the other day, and immediately plugged them into my ipod. Please don't let the breaking in period discourage you! After these become comfortable, you will hear music you have never heard before even when you are listening to songs you have heard thousands of time.\n",
      "\n",
      "I started with all my heavy bass tracks, and couldn't believe how they sounded with these headphones. I then wanted to try some of my jazz and blues tracks to see how these tracks sounded. This is the first time in my life John Coltrane has given me goosebumps!\n",
      "\n",
      "If you are debating on whether to spend this kind of money let me make it easy for you. If you are just a casual music listener, I would say just go with a good pair of cheap ones, you will save a lot of money. However if you are a passionate music lover and collector, these headphones will change your music completely. After getting comfortable with these, I would have paid much more than I actually did\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 找出歸類錯誤的例子\n",
    "preds = model.predict(X)\n",
    "P = model.predict_proba(X)[:,1] # p(y = 1 | x)\n",
    "\n",
    "# 只列出最糟的\n",
    "minP_whenYis1 = 1\n",
    "maxP_whenYis0 = 0\n",
    "wrong_positive_review = None\n",
    "wrong_negative_review = None\n",
    "wrong_positive_prediction = None\n",
    "wrong_negative_prediction = None\n",
    "for i in range(N):\n",
    "    p = P[i]\n",
    "    y = Y[i]\n",
    "    if y == 1 and p < 0.5:\n",
    "        if p < minP_whenYis1:\n",
    "            wrong_positive_review = orig_reviews[i]\n",
    "            wrong_positive_prediction = preds[i]\n",
    "            minP_whenYis1 = p\n",
    "    elif y == 0 and p > 0.5:\n",
    "        if p > maxP_whenYis0:\n",
    "            wrong_negative_review = orig_reviews[i]\n",
    "            wrong_negative_prediction = preds[i]\n",
    "            maxP_whenYis0 = p\n",
    "\n",
    "print(\"Most wrong positive review (prob = %s, pred = %s):\" % (minP_whenYis1, wrong_positive_prediction))\n",
    "print(wrong_positive_review)\n",
    "print(\"Most wrong negative review (prob = %s, pred = %s):\" % (maxP_whenYis0, wrong_negative_prediction))\n",
    "print(wrong_negative_review)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
